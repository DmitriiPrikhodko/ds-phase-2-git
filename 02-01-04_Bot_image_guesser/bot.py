import logging
import os
import io
import asyncio
import multiprocessing as mp

import torch
from torch import nn
from torchvision import transforms as T
from torchvision.models import convnext_tiny
from PIL import Image

from aiogram import Bot, Dispatcher, types, F
from aiogram.types import Message
from aiogram.filters import Command

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ multiprocessing ---
if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PyTorch ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.set_default_device(DEVICE)

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
os.makedirs("./log", exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    filename="./log/bot_log.log",
    format="%(asctime)s - %(levelname)s - %(funcName)s: %(lineno)d - %(message)s",
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
logging.getLogger("").addHandler(console)

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
TOKEN = "8369392797:AAHwTSC8JnwL8INDF-hOnuyzzKC3RqU_2wI"
WEIGHTS_PATH = "./weights/weights.pth"

CLASSES = {
    0: "–∞–ª—Ç–∞—Ä—å",
    1: "–∞–ø—Å–∏–¥–∞",
    2: "–∫–æ–ª–æ–∫–æ–ª—å–Ω—è",
    3: "–∫–æ–ª–æ–Ω–Ω–∞",
    4: "–∫—É–ø–æ–ª (–≤–Ω—É—Ç—Ä–∏)",
    5: "–∫—É–ø–æ–ª (—Å–Ω–∞—Ä—É–∂–∏)",
    6: "–∞—Ä–∫–±—É—Ç–∞–Ω",
    7: "–≥–∞—Ä–≥—É–ª—å—è",
    8: "–≤–∏—Ç—Ä–∞–∂",
    9: "—Å–≤–æ–¥",
}

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
model = None
transform = None


def load_model(weights_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    logging.info("–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")
    m = convnext_tiny()
    m.to(DEVICE)
    m.classifier[2] = nn.Linear(768, 10)
    m.load_state_dict(torch.load(weights_path, map_location=DEVICE))
    m.eval()
    logging.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    return m


def create_transform():
    """–°–æ–∑–¥–∞—ë—Ç –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π"""
    return T.Compose(
        [
            T.Resize((224, 224)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )


def get_prediction(img: Image.Image):
    """–î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"""
    img_tensor = transform(img).unsqueeze(0).to(DEVICE)
    with torch.inference_mode():
        output = model(img_tensor)
        pred_idx = torch.argmax(output, dim=1).item()
        confidence = torch.softmax(output, dim=1)[0][pred_idx].item()
    return CLASSES.get(pred_idx, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"), confidence


async def download_photo(bot: Bot, file_id: str) -> Image.Image:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–æ—Ç–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç PIL Image"""
    file = await bot.get_file(file_id)
    photo_bytes = await bot.download_file(file.file_path)
    return Image.open(photo_bytes)


async def process_single_photo(bot: Bot, photo: types.PhotoSize, index: int):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Ñ–æ—Ç–æ"""
    try:
        image = await download_photo(bot, photo.file_id)
        pred_class, confidence = get_prediction(image)
        return {
            "index": index,
            "pred_class": pred_class,
            "confidence": confidence,
            "success": True,
        }
    except Exception as e:
        return {"index": index, "error": str(e), "success": False}


# --- –•—ç–Ω–¥–ª–µ—Ä—ã ---


async def cmd_start(message: Message):
    user_name = message.from_user.full_name
    logging.info(f"{user_name} ({message.from_user.id}) –∑–∞–ø—É—Å—Ç–∏–ª –±–æ—Ç–∞")
    await message.answer(
        f"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, {user_name}!\n"
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞—Ä—Ç–∏–Ω–∫—É, –∏ —è —Å–∫–∞–∂—É, —á—Ç–æ –Ω–∞ –Ω–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ.\n"
        "–ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ —Å—Ä–∞–∑—É!"
    )


async def text_answer(message: Message):
    user_name = message.from_user.full_name
    logging.info(f"{user_name} ({message.from_user.id}) –Ω–∞–ø–∏—Å–∞–ª: {message.text}")
    await message.answer("–Ø –Ω–µ —É–º–µ—é —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å, —É–º–µ—é —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ üñºÔ∏è")


async def handle_photo(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ ‚Äî –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç message.photo)"""
    user_name = message.from_user.full_name
    logging.info(f"{user_name} –∑–∞–≥—Ä—É–∑–∏–ª —Ñ–æ—Ç–æ ({len(message.photo)} —Ä–∞–∑–º–µ—Ä–æ–≤)")

    processing_msg = await message.answer("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ...")

    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é (–ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç)
    photo = message.photo[-1]
    result = await process_single_photo(message.bot, photo, 0)

    if result["success"]:
        response = (
            f"üì∏ –§–æ—Ç–æ:\n"
            f"üè∑Ô∏è –ö–ª–∞—Å—Å: {result['pred_class']}\n"
            f"‚úÖ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2%}"
        )
    else:
        response = f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['error']}"

    await processing_msg.delete()
    await message.answer(response)


async def handle_album(messages: list[Message]):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª—å–±–æ–º–∞ (–Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–æ—Ç–æ –∑–∞ —Ä–∞–∑)"""
    bot = messages[0].bot
    user_name = messages[0].from_user.full_name
    logging.info(f"{user_name} –∑–∞–≥—Ä—É–∑–∏–ª –∞–ª—å–±–æ–º –∏–∑ {len(messages)} —Ñ–æ—Ç–æ")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    processing_msg = await messages[0].answer(f"‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(messages)} —Ñ–æ—Ç–æ...")

    # –ë–µ—Ä—ë–º –ø–æ –æ–¥–Ω–æ–º—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ñ–æ—Ç–æ –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    tasks = [process_single_photo(bot, m.photo[-1], i) for i, m in enumerate(messages)]
    results = await asyncio.gather(*tasks)

    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]

    response = f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(messages)} —Ñ–æ—Ç–æ:\n\n"
    for r in successful:
        response += (
            f"üì∏ –§–æ—Ç–æ {r['index']+1}:\n"
            f"   üè∑Ô∏è –ö–ª–∞—Å—Å: {r['pred_class']}\n"
            f"   ‚úÖ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {r['confidence']:.2%}\n"
            f"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
        )
    if failed:
        response += f"\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å {len(failed)} —Ñ–æ—Ç–æ\n"

    response += f"\nüìà –ò—Ç–æ–≥–æ: {len(successful)} —É—Å–ø–µ—à–Ω–æ, {len(failed)} —Å –æ—à–∏–±–∫–∞–º–∏"

    await processing_msg.delete()
    await messages[0].answer(response)


async def handle_document(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∫–∞–∫ —Ñ–∞–π–ª—ã"""
    if message.document.mime_type and message.document.mime_type.startswith("image/"):
        try:
            image = await download_photo(message.bot, message.document.file_id)
            pred_class, confidence = get_prediction(image)
            await message.answer(
                f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–¥–æ–∫—É–º–µ–Ω—Ç):\n"
                f"üìä –ö–ª–∞—Å—Å: {pred_class}\n"
                f"‚úÖ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}"
            )
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞.")


async def main():
    global model, transform
    model = load_model(WEIGHTS_PATH)
    transform = create_transform()

    bot = Bot(token=TOKEN)
    dp = Dispatcher()

    dp.message.register(cmd_start, Command("start"))
    dp.message.register(text_answer, F.text)
    dp.message.register(handle_photo, F.photo)
    dp.message.register(handle_document, F.document)

    logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω üöÄ")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
